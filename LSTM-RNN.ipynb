{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ae74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfaa248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_len = 25253\n",
    "# validation_len = 9471\n",
    "# test_len = 13794\n",
    "train_length = 2684\n",
    "val_length = 726\n",
    "test_length = 1498\n",
    "\n",
    "def load_features(filename,\n",
    "                  skip_header=True,\n",
    "                  skip_instname=True,\n",
    "                  delim=' ',\n",
    "                  num_lines=0):\n",
    "    if num_lines == 0:\n",
    "        num_lines = get_num_lines(filename, skip_header)\n",
    "\n",
    "    data = np.empty(\n",
    "        (num_lines, 50), float)\n",
    "\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        if skip_header:\n",
    "            next(csv_file)\n",
    "        c = 0\n",
    "        for line in tqdm(csv_file):\n",
    "            offset = 0\n",
    "            if skip_instname:\n",
    "                offset = line.find(delim) + 1\n",
    "            data[c, :] = np.fromstring(line[offset:], dtype=float, sep=delim)\n",
    "            c += 1\n",
    "\n",
    "    return data\n",
    "\n",
    "def load_batch_features(filename, start_index=0, amount=0):\n",
    "    delim = ' '\n",
    "    \n",
    "    data = np.empty((amount, 25), float)\n",
    "    \n",
    "    with open(filename, 'r') as csv_file:\n",
    "        for i, line in tqdm(enumerate(csv_file)):\n",
    "            if i < start_index:\n",
    "                continue\n",
    "            if i >= start_index + amount:\n",
    "                break\n",
    "            index = i - start_index\n",
    "            data[index, :] = np.fromstring(line, dtype=float, sep=delim)\n",
    "    return data\n",
    "    \n",
    "def load_batch_labels(filename, start_index=1, amount=0):\n",
    "    labels = np.empty((amount, 3), float)\n",
    "    delim = ','\n",
    "    \n",
    "    with open(filename, 'r') as csv_file:\n",
    "        for i, line in tqdm(enumerate(csv_file)):\n",
    "            if i < start_index:\n",
    "                continue\n",
    "            if i >= start_index + amount:\n",
    "                break\n",
    "            cols = np.fromstring(line, dtype=float, sep=delim)\n",
    "            index = i - start_index\n",
    "            labels[index, :] = cols[1:]\n",
    "    return labels\n",
    "    \n",
    "def get_num_lines(filename, skip_header):\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        if skip_header:\n",
    "            next(csv_file)\n",
    "        c = 0\n",
    "        for line in csv_file:\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def load_labels(filename,\n",
    "                  skip_header=True,\n",
    "                  skip_instname=True,\n",
    "                  delim=' ',\n",
    "                  num_lines=0):\n",
    "    if num_lines == 0:\n",
    "        num_lines = get_num_lines(filename, skip_header)\n",
    "\n",
    "    data = np.empty(\n",
    "        (num_lines, 3), float)\n",
    "\n",
    "    with open(filename, 'r') as csv_file:\n",
    "        if skip_header:\n",
    "            next(csv_file)\n",
    "        c = 0\n",
    "        for line in tqdm(csv_file):\n",
    "            offset = 0\n",
    "            if skip_instname:\n",
    "                offset = line.find(delim) + 1\n",
    "            data[c, :] = np.fromstring(line[offset:], dtype=float, sep=delim)\n",
    "            c += 1\n",
    "\n",
    "    return data\n",
    "    \n",
    "    \n",
    "def get_scaler(x):\n",
    "    x_scaler = StandardScaler()\n",
    "    x_scaler.fit(x)\n",
    "  \n",
    "    return x_scaler\n",
    "\n",
    "def scale_data(scaler, data):\n",
    "    if data.ndim > 2:\n",
    "        data = data.reshape(-1, data.shape[2])\n",
    "    scaled = scaler.transform(data)\n",
    "    \n",
    "    return scaled\n",
    "\n",
    "def ccc(gold, pred):\n",
    "    gold       = K.squeeze(gold, axis=-1)\n",
    "    pred       = K.squeeze(pred, axis=-1)\n",
    "    gold_mean  = K.mean(gold, axis=-1, keepdims=True)\n",
    "    pred_mean  = K.mean(pred, axis=-1, keepdims=True)\n",
    "    covariance = (gold-gold_mean)*(pred-pred_mean)\n",
    "    gold_var   = K.mean(K.square(gold-gold_mean), axis=-1,  keepdims=True)\n",
    "    pred_var   = K.mean(K.square(pred-pred_mean), axis=-1, keepdims=True)\n",
    "    ccc        = K.constant(2.) * covariance / (gold_var + pred_var + K.square(gold_mean - pred_mean) + K.epsilon())\n",
    "    return ccc\n",
    "\n",
    "def ccc_loss(gold, pred):\n",
    "    ccc_loss = K.constant(1.) - ccc(gold, pred)\n",
    "    return ccc_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d39c15",
   "metadata": {},
   "source": [
    "### Batch loading to train LSTM-RNN\n",
    "\n",
    "- First, load all data to get scalers that covers for each partition data\n",
    "- Batching the data to train\n",
    "- Batching the data to validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5f69b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1041392it [00:10, 96386.43it/s]\n",
      "1041392it [00:02, 395019.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading finished, Scaling...\n",
      "x_train shape: (2684, 388, 50)\n",
      "y_train shape: (2684, 388, 3)\n",
      "End of loading and preprocessing training samples\n",
      "Loading validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "281688it [00:02, 97375.12it/s] \n",
      "281688it [00:00, 387605.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading finished, Scaling...\n",
      "x_validation shape: (726, 388, 50)\n",
      "y_validation shape: (726, 388, 3)\n",
      "End of loading and preprocessing validation samples\n",
      "Loading testing samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "581224it [00:05, 97845.87it/s] \n",
      "581224it [00:01, 391790.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading finished, Scaling...\n",
      "x_test shape: (1498, 388, 50)\n",
      "y_test shape: (1498, 388, 3)\n",
      "End of loading and preprocessing test samples\n"
     ]
    }
   ],
   "source": [
    "data_path = './Functional_features/'\n",
    "\n",
    "seq_len = 388\n",
    "n_features = 25\n",
    "\n",
    "\n",
    "# load all data to get a scaler that covers all data\n",
    "print(\"Loading training samples...\")\n",
    "x_train = load_features(data_path+'train.txt', skip_header=False, skip_instname=False)\n",
    "train_labels = load_labels(data_path+'train_labels.txt', skip_header=False, skip_instname=False)\n",
    "y_train = train_labels.reshape((train_length, seq_len, 3))\n",
    "\n",
    "print(\"Loading finished, Scaling...\")\n",
    "x_scaler = get_scaler(x_train)\n",
    "\n",
    "# Scaling acoustic features\n",
    "x_train_scaled = scale_data(x_scaler, x_train)\n",
    "# Scaling labels from [-100,100] to [-1, 1]\n",
    "f = lambda x: x * 0.01\n",
    "y_train_scaled = f(y_train)\n",
    "x_train_scaled = x_train_scaled.reshape((train_length, seq_len, n_features * 2))\n",
    "print('x_train shape:', x_train_scaled.shape)\n",
    "print('y_train shape:', y_train_scaled.shape)\n",
    "print(\"End of loading and preprocessing training samples\")\n",
    "\n",
    "print(\"Loading validation samples...\")\n",
    "x_validation = load_features(data_path+'validation.txt', skip_header = False, skip_instname=False)\n",
    "val_labels = load_labels(data_path+'validation_labels.txt', skip_header=False, skip_instname=False)\n",
    "y_validation = val_labels.reshape((val_length, seq_len, 3))\n",
    "print(\"Loading finished, Scaling...\")\n",
    "x_val_scaled = scale_data(x_scaler, x_validation)\n",
    "y_val_scaled = f(y_validation)\n",
    "x_val_scaled = x_val_scaled.reshape((val_length, seq_len, n_features * 2))\n",
    "\n",
    "print('x_validation shape:', x_val_scaled.shape)\n",
    "print('y_validation shape:', y_val_scaled.shape)\n",
    "print(\"End of loading and preprocessing validation samples\")\n",
    "\n",
    "print(\"Loading testing samples...\")\n",
    "x_test = load_features(data_path+'test.txt', skip_header = False, skip_instname=False)\n",
    "test_labels = load_labels(data_path+'test_labels.txt', skip_header=False, skip_instname=False)\n",
    "y_test = test_labels.reshape((test_length, seq_len, 3))\n",
    "print(\"Loading finished, Scaling...\")\n",
    "x_test_scaled = scale_data(x_scaler, x_test)\n",
    "y_test_scaled = f(y_test)\n",
    "x_test_scaled = x_test_scaled.reshape((test_length, seq_len, n_features * 2))\n",
    "\n",
    "print('x_test shape:', x_test_scaled.shape)\n",
    "print('y_test shape:', y_test_scaled.shape)\n",
    "print(\"End of loading and preprocessing test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a161c73-9701-4ff4-ad61-cc24fc47aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = y_train.columns\n",
    "# print(headers)\n",
    "headers = ['Arousal', 'Valence', 'Dominance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbeed576-7055-44b8-b324-d2c887cd50f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2684"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13dc203",
   "metadata": {},
   "source": [
    "### Building RNN-LSTM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3bb6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model, save_model, load_model, Sequential\n",
    "from keras.layers import Input, Dense, Masking, LSTM, Dropout, TimeDistributed, Bidirectional, Flatten, Embedding, Conv1D, BatchNormalization, MaxPool1D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d1e34a-531f-484a-a58e-8fe1b733ba38",
   "metadata": {},
   "source": [
    "### Multi-task learning\n",
    "\n",
    "three models are integrated and each model covers Arousal, Valence, Dominance respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "40323eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_length = 25253\n",
    "# val_length = 9471\n",
    "# test_length = 13794\n",
    "# train_length = 41815\n",
    "# val_length = 13451\n",
    "# test_length = 22633\n",
    "\n",
    "n_features = 50\n",
    "random_seed = 42\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def create_model(n_units1=64, n_units2=32):\n",
    "    model = Sequential()\n",
    "    inputs = Input(shape=(seq_len, n_features), dtype=float)\n",
    "    mask = Masking()(inputs)\n",
    "    lstm_1 = LSTM(n_units1, return_sequences=True)(mask)\n",
    "    lstm_2 = LSTM(n_units2, return_sequences=True)(lstm_1)\n",
    "    modes = lstm_2\n",
    "    output = [TimeDistributed(Dense(1), name=name)(modes) for i, name in enumerate(headers)]\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    rmsprop = RMSprop(lr=0.0001)\n",
    "    model.compile(optimizer=rmsprop, loss=ccc_loss, metrics=[ccc])\n",
    "    return model\n",
    "#\n",
    "# def create_arousal(n_units1=64, n_units2=32, dropout, bidirection=False):\n",
    "#     a_input = Input(shape=(time_step, n_features), dtype=float, name='arousal_model_input')\n",
    "#     mask = Masking()(a_input)\n",
    "#     if bidirection:\n",
    "#         a_lstm1 = Bidirectional(LSTM(n_units1, return_sequences=True))(mask)\n",
    "#     else:\n",
    "#         a_lstm1 = LSTM(n_units1, return_sequences=True)(mask)\n",
    "#     a_lstm1 = Dropout(dropout)(a_lstm1)\n",
    "#     if bidirection:\n",
    "#         a_lstm2 = Bidirectional(LSTM(n_units2, return_sequences=False)(a_lstm1))\n",
    "#     else:\n",
    "#         a_lstm2 = LSTM(n_units2, return_sequences=False)(a_lstm1)\n",
    "#     a_lstm2 = Dropout(dropout)(a_lstm2)\n",
    "#     a_dense = Dense(\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f00a9428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 388, 50)]    0           []                               \n",
      "                                                                                                  \n",
      " masking_11 (Masking)           (None, 388, 50)      0           ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_21 (LSTM)                 (None, 388, 64)      29440       ['masking_11[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_22 (LSTM)                 (None, 388, 32)      12416       ['lstm_21[0][0]']                \n",
      "                                                                                                  \n",
      " Arousal (TimeDistributed)      (None, 388, 1)       33          ['lstm_22[0][0]']                \n",
      "                                                                                                  \n",
      " Valence (TimeDistributed)      (None, 388, 1)       33          ['lstm_22[0][0]']                \n",
      "                                                                                                  \n",
      " Dominance (TimeDistributed)    (None, 388, 1)       33          ['lstm_22[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 41,955\n",
      "Trainable params: 41,955\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_model(n_units1=64, n_units2=32)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4abb3d5e-c60d-47a0-9075-24e298491c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b74c5d-8863-4cf4-a185-e06d54cfed38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131463</td>\n",
       "      <td>0.130148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.120476</td>\n",
       "      <td>0.131123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.112240</td>\n",
       "      <td>0.131850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.107064</td>\n",
       "      <td>0.124378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099479</td>\n",
       "      <td>0.121350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41810</th>\n",
       "      <td>0.220442</td>\n",
       "      <td>0.146308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41811</th>\n",
       "      <td>0.224396</td>\n",
       "      <td>0.147028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41812</th>\n",
       "      <td>0.229963</td>\n",
       "      <td>0.150131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41813</th>\n",
       "      <td>0.236319</td>\n",
       "      <td>0.156082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41814</th>\n",
       "      <td>0.245087</td>\n",
       "      <td>0.166378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41815 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Arousal  Dominance\n",
       "0      0.131463   0.130148\n",
       "1      0.120476   0.131123\n",
       "2      0.112240   0.131850\n",
       "3      0.107064   0.124378\n",
       "4      0.099479   0.121350\n",
       "...         ...        ...\n",
       "41810  0.220442   0.146308\n",
       "41811  0.224396   0.147028\n",
       "41812  0.229963   0.150131\n",
       "41813  0.236319   0.156082\n",
       "41814  0.245087   0.166378\n",
       "\n",
       "[41815 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.loc[:,['Arousal', 'Dominance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "083ca975-8a26-44bd-93af-12976345c280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2684, 388, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dta = []\n",
    "y_val_dta = []\n",
    "\n",
    "index = [0,1,2]\n",
    "for i in index:\n",
    "    dim = np.empty((train_length, seq_len, 1))\n",
    "    dim[:,:,0] = y_train_scaled[:,:,i]\n",
    "    y_train_dta.append(dim)\n",
    "    val_dim = np.empty((val_length, seq_len, 1))\n",
    "    val_dim[:,:,0] = y_val_scaled[:,:,i]\n",
    "    y_val_dta.append(val_dim)\n",
    "y_train_dta[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4fb1de9f-1166-44b2-b7da-f94878d5de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84/84 [==============================] - 15s 75ms/step - loss: 2.2320 - Arousal_loss: 0.3740 - Valence_loss: 1.0250 - Dominance_loss: 0.8329 - Arousal_ccc: 0.6260 - Valence_ccc: -0.0250 - Dominance_ccc: 0.1671 - val_loss: 1.8593 - val_Arousal_loss: 0.3626 - val_Valence_loss: 1.0190 - val_Dominance_loss: 0.4777 - val_Arousal_ccc: 0.6374 - val_Valence_ccc: -0.0190 - val_Dominance_ccc: 0.5223\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 1.5331 - Arousal_loss: 0.2910 - Valence_loss: 1.0048 - Dominance_loss: 0.2373 - Arousal_ccc: 0.7090 - Valence_ccc: -0.0048 - Dominance_ccc: 0.7627 - val_loss: 1.5948 - val_Arousal_loss: 0.2913 - val_Valence_loss: 0.9954 - val_Dominance_loss: 0.3081 - val_Arousal_ccc: 0.7087 - val_Valence_ccc: 0.0046 - val_Dominance_ccc: 0.6919\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.2954 - Arousal_loss: 0.2562 - Valence_loss: 0.8545 - Dominance_loss: 0.1846 - Arousal_ccc: 0.7438 - Valence_ccc: 0.1455 - Dominance_ccc: 0.8154 - val_loss: 1.4763 - val_Arousal_loss: 0.2458 - val_Valence_loss: 0.9539 - val_Dominance_loss: 0.2766 - val_Arousal_ccc: 0.7542 - val_Valence_ccc: 0.0461 - val_Dominance_ccc: 0.7234\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.1277 - Arousal_loss: 0.2339 - Valence_loss: 0.7266 - Dominance_loss: 0.1671 - Arousal_ccc: 0.7661 - Valence_ccc: 0.2734 - Dominance_ccc: 0.8329 - val_loss: 1.4555 - val_Arousal_loss: 0.2413 - val_Valence_loss: 0.9527 - val_Dominance_loss: 0.2615 - val_Arousal_ccc: 0.7587 - val_Valence_ccc: 0.0473 - val_Dominance_ccc: 0.7385\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.0674 - Arousal_loss: 0.2194 - Valence_loss: 0.6924 - Dominance_loss: 0.1556 - Arousal_ccc: 0.7806 - Valence_ccc: 0.3076 - Dominance_ccc: 0.8444 - val_loss: 1.3619 - val_Arousal_loss: 0.2205 - val_Valence_loss: 0.9256 - val_Dominance_loss: 0.2157 - val_Arousal_ccc: 0.7795 - val_Valence_ccc: 0.0744 - val_Dominance_ccc: 0.7843\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 1.0255 - Arousal_loss: 0.2101 - Valence_loss: 0.6672 - Dominance_loss: 0.1482 - Arousal_ccc: 0.7899 - Valence_ccc: 0.3328 - Dominance_ccc: 0.8518 - val_loss: 1.3585 - val_Arousal_loss: 0.2230 - val_Valence_loss: 0.9271 - val_Dominance_loss: 0.2084 - val_Arousal_ccc: 0.7770 - val_Valence_ccc: 0.0729 - val_Dominance_ccc: 0.7916\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.9981 - Arousal_loss: 0.2046 - Valence_loss: 0.6511 - Dominance_loss: 0.1424 - Arousal_ccc: 0.7954 - Valence_ccc: 0.3489 - Dominance_ccc: 0.8576 - val_loss: 1.3322 - val_Arousal_loss: 0.2069 - val_Valence_loss: 0.9177 - val_Dominance_loss: 0.2075 - val_Arousal_ccc: 0.7931 - val_Valence_ccc: 0.0823 - val_Dominance_ccc: 0.7925\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.9757 - Arousal_loss: 0.1981 - Valence_loss: 0.6391 - Dominance_loss: 0.1384 - Arousal_ccc: 0.8019 - Valence_ccc: 0.3609 - Dominance_ccc: 0.8616 - val_loss: 1.3337 - val_Arousal_loss: 0.2006 - val_Valence_loss: 0.9499 - val_Dominance_loss: 0.1832 - val_Arousal_ccc: 0.7994 - val_Valence_ccc: 0.0501 - val_Dominance_ccc: 0.8168\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.9573 - Arousal_loss: 0.1936 - Valence_loss: 0.6298 - Dominance_loss: 0.1339 - Arousal_ccc: 0.8064 - Valence_ccc: 0.3702 - Dominance_ccc: 0.8661 - val_loss: 1.3379 - val_Arousal_loss: 0.1962 - val_Valence_loss: 0.9625 - val_Dominance_loss: 0.1793 - val_Arousal_ccc: 0.8038 - val_Valence_ccc: 0.0375 - val_Dominance_ccc: 0.8207\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.9420 - Arousal_loss: 0.1916 - Valence_loss: 0.6176 - Dominance_loss: 0.1328 - Arousal_ccc: 0.8084 - Valence_ccc: 0.3824 - Dominance_ccc: 0.8672 - val_loss: 1.3331 - val_Arousal_loss: 0.1963 - val_Valence_loss: 0.9631 - val_Dominance_loss: 0.1737 - val_Arousal_ccc: 0.8037 - val_Valence_ccc: 0.0369 - val_Dominance_ccc: 0.8263\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.9263 - Arousal_loss: 0.1876 - Valence_loss: 0.6090 - Dominance_loss: 0.1297 - Arousal_ccc: 0.8124 - Valence_ccc: 0.3910 - Dominance_ccc: 0.8703 - val_loss: 1.2840 - val_Arousal_loss: 0.1878 - val_Valence_loss: 0.9257 - val_Dominance_loss: 0.1704 - val_Arousal_ccc: 0.8122 - val_Valence_ccc: 0.0743 - val_Dominance_ccc: 0.8296\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.9210 - Arousal_loss: 0.1856 - Valence_loss: 0.6083 - Dominance_loss: 0.1271 - Arousal_ccc: 0.8144 - Valence_ccc: 0.3917 - Dominance_ccc: 0.8729 - val_loss: 1.3089 - val_Arousal_loss: 0.1881 - val_Valence_loss: 0.9520 - val_Dominance_loss: 0.1688 - val_Arousal_ccc: 0.8119 - val_Valence_ccc: 0.0480 - val_Dominance_ccc: 0.8312\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.9100 - Arousal_loss: 0.1825 - Valence_loss: 0.6033 - Dominance_loss: 0.1241 - Arousal_ccc: 0.8175 - Valence_ccc: 0.3967 - Dominance_ccc: 0.8759 - val_loss: 1.2912 - val_Arousal_loss: 0.1860 - val_Valence_loss: 0.9415 - val_Dominance_loss: 0.1636 - val_Arousal_ccc: 0.8140 - val_Valence_ccc: 0.0585 - val_Dominance_ccc: 0.8364\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.9017 - Arousal_loss: 0.1818 - Valence_loss: 0.5966 - Dominance_loss: 0.1233 - Arousal_ccc: 0.8182 - Valence_ccc: 0.4034 - Dominance_ccc: 0.8767 - val_loss: 1.2997 - val_Arousal_loss: 0.1890 - val_Valence_loss: 0.9519 - val_Dominance_loss: 0.1588 - val_Arousal_ccc: 0.8110 - val_Valence_ccc: 0.0481 - val_Dominance_ccc: 0.8412\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8940 - Arousal_loss: 0.1809 - Valence_loss: 0.5913 - Dominance_loss: 0.1218 - Arousal_ccc: 0.8191 - Valence_ccc: 0.4087 - Dominance_ccc: 0.8782 - val_loss: 1.2922 - val_Arousal_loss: 0.1825 - val_Valence_loss: 0.9336 - val_Dominance_loss: 0.1761 - val_Arousal_ccc: 0.8175 - val_Valence_ccc: 0.0664 - val_Dominance_ccc: 0.8239\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.8907 - Arousal_loss: 0.1794 - Valence_loss: 0.5909 - Dominance_loss: 0.1205 - Arousal_ccc: 0.8206 - Valence_ccc: 0.4091 - Dominance_ccc: 0.8795 - val_loss: 1.2806 - val_Arousal_loss: 0.1832 - val_Valence_loss: 0.9373 - val_Dominance_loss: 0.1600 - val_Arousal_ccc: 0.8168 - val_Valence_ccc: 0.0627 - val_Dominance_ccc: 0.8400\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8788 - Arousal_loss: 0.1770 - Valence_loss: 0.5825 - Dominance_loss: 0.1192 - Arousal_ccc: 0.8230 - Valence_ccc: 0.4175 - Dominance_ccc: 0.8808 - val_loss: 1.2799 - val_Arousal_loss: 0.1847 - val_Valence_loss: 0.9425 - val_Dominance_loss: 0.1528 - val_Arousal_ccc: 0.8153 - val_Valence_ccc: 0.0575 - val_Dominance_ccc: 0.8472\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.8750 - Arousal_loss: 0.1761 - Valence_loss: 0.5806 - Dominance_loss: 0.1183 - Arousal_ccc: 0.8239 - Valence_ccc: 0.4194 - Dominance_ccc: 0.8817 - val_loss: 1.2945 - val_Arousal_loss: 0.1905 - val_Valence_loss: 0.9436 - val_Dominance_loss: 0.1605 - val_Arousal_ccc: 0.8095 - val_Valence_ccc: 0.0564 - val_Dominance_ccc: 0.8395\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8697 - Arousal_loss: 0.1760 - Valence_loss: 0.5766 - Dominance_loss: 0.1171 - Arousal_ccc: 0.8240 - Valence_ccc: 0.4234 - Dominance_ccc: 0.8829 - val_loss: 1.2811 - val_Arousal_loss: 0.1775 - val_Valence_loss: 0.9487 - val_Dominance_loss: 0.1549 - val_Arousal_ccc: 0.8225 - val_Valence_ccc: 0.0513 - val_Dominance_ccc: 0.8451\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8681 - Arousal_loss: 0.1760 - Valence_loss: 0.5757 - Dominance_loss: 0.1163 - Arousal_ccc: 0.8240 - Valence_ccc: 0.4243 - Dominance_ccc: 0.8837 - val_loss: 1.2927 - val_Arousal_loss: 0.1787 - val_Valence_loss: 0.9654 - val_Dominance_loss: 0.1486 - val_Arousal_ccc: 0.8213 - val_Valence_ccc: 0.0346 - val_Dominance_ccc: 0.8514\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8587 - Arousal_loss: 0.1753 - Valence_loss: 0.5690 - Dominance_loss: 0.1145 - Arousal_ccc: 0.8247 - Valence_ccc: 0.4310 - Dominance_ccc: 0.8855 - val_loss: 1.2980 - val_Arousal_loss: 0.1818 - val_Valence_loss: 0.9504 - val_Dominance_loss: 0.1658 - val_Arousal_ccc: 0.8182 - val_Valence_ccc: 0.0496 - val_Dominance_ccc: 0.8342\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8574 - Arousal_loss: 0.1742 - Valence_loss: 0.5682 - Dominance_loss: 0.1150 - Arousal_ccc: 0.8258 - Valence_ccc: 0.4318 - Dominance_ccc: 0.8850 - val_loss: 1.2710 - val_Arousal_loss: 0.1768 - val_Valence_loss: 0.9397 - val_Dominance_loss: 0.1544 - val_Arousal_ccc: 0.8232 - val_Valence_ccc: 0.0603 - val_Dominance_ccc: 0.8456\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8499 - Arousal_loss: 0.1728 - Valence_loss: 0.5629 - Dominance_loss: 0.1142 - Arousal_ccc: 0.8272 - Valence_ccc: 0.4371 - Dominance_ccc: 0.8858 - val_loss: 1.2989 - val_Arousal_loss: 0.1882 - val_Valence_loss: 0.9650 - val_Dominance_loss: 0.1457 - val_Arousal_ccc: 0.8118 - val_Valence_ccc: 0.0350 - val_Dominance_ccc: 0.8543\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.8483 - Arousal_loss: 0.1725 - Valence_loss: 0.5629 - Dominance_loss: 0.1129 - Arousal_ccc: 0.8275 - Valence_ccc: 0.4371 - Dominance_ccc: 0.8871 - val_loss: 1.2621 - val_Arousal_loss: 0.1775 - val_Valence_loss: 0.9362 - val_Dominance_loss: 0.1485 - val_Arousal_ccc: 0.8225 - val_Valence_ccc: 0.0638 - val_Dominance_ccc: 0.8515\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8428 - Arousal_loss: 0.1718 - Valence_loss: 0.5584 - Dominance_loss: 0.1126 - Arousal_ccc: 0.8282 - Valence_ccc: 0.4416 - Dominance_ccc: 0.8874 - val_loss: 1.2886 - val_Arousal_loss: 0.1783 - val_Valence_loss: 0.9454 - val_Dominance_loss: 0.1650 - val_Arousal_ccc: 0.8217 - val_Valence_ccc: 0.0546 - val_Dominance_ccc: 0.8350\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.8404 - Arousal_loss: 0.1720 - Valence_loss: 0.5568 - Dominance_loss: 0.1117 - Arousal_ccc: 0.8280 - Valence_ccc: 0.4432 - Dominance_ccc: 0.8883 - val_loss: 1.3005 - val_Arousal_loss: 0.1817 - val_Valence_loss: 0.9537 - val_Dominance_loss: 0.1651 - val_Arousal_ccc: 0.8183 - val_Valence_ccc: 0.0463 - val_Dominance_ccc: 0.8349\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8356 - Arousal_loss: 0.1706 - Valence_loss: 0.5537 - Dominance_loss: 0.1113 - Arousal_ccc: 0.8294 - Valence_ccc: 0.4463 - Dominance_ccc: 0.8887 - val_loss: 1.2532 - val_Arousal_loss: 0.1746 - val_Valence_loss: 0.9346 - val_Dominance_loss: 0.1440 - val_Arousal_ccc: 0.8254 - val_Valence_ccc: 0.0654 - val_Dominance_ccc: 0.8560\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8310 - Arousal_loss: 0.1701 - Valence_loss: 0.5500 - Dominance_loss: 0.1109 - Arousal_ccc: 0.8299 - Valence_ccc: 0.4500 - Dominance_ccc: 0.8891 - val_loss: 1.2589 - val_Arousal_loss: 0.1764 - val_Valence_loss: 0.9381 - val_Dominance_loss: 0.1444 - val_Arousal_ccc: 0.8236 - val_Valence_ccc: 0.0619 - val_Dominance_ccc: 0.8556\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8282 - Arousal_loss: 0.1690 - Valence_loss: 0.5492 - Dominance_loss: 0.1100 - Arousal_ccc: 0.8310 - Valence_ccc: 0.4508 - Dominance_ccc: 0.8900 - val_loss: 1.2612 - val_Arousal_loss: 0.1739 - val_Valence_loss: 0.9441 - val_Dominance_loss: 0.1432 - val_Arousal_ccc: 0.8261 - val_Valence_ccc: 0.0559 - val_Dominance_ccc: 0.8568\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8262 - Arousal_loss: 0.1693 - Valence_loss: 0.5472 - Dominance_loss: 0.1096 - Arousal_ccc: 0.8307 - Valence_ccc: 0.4528 - Dominance_ccc: 0.8904 - val_loss: 1.2694 - val_Arousal_loss: 0.1746 - val_Valence_loss: 0.9515 - val_Dominance_loss: 0.1433 - val_Arousal_ccc: 0.8254 - val_Valence_ccc: 0.0485 - val_Dominance_ccc: 0.8567\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8204 - Arousal_loss: 0.1683 - Valence_loss: 0.5424 - Dominance_loss: 0.1096 - Arousal_ccc: 0.8317 - Valence_ccc: 0.4576 - Dominance_ccc: 0.8904 - val_loss: 1.2633 - val_Arousal_loss: 0.1755 - val_Valence_loss: 0.9425 - val_Dominance_loss: 0.1453 - val_Arousal_ccc: 0.8245 - val_Valence_ccc: 0.0575 - val_Dominance_ccc: 0.8547\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.8175 - Arousal_loss: 0.1681 - Valence_loss: 0.5399 - Dominance_loss: 0.1095 - Arousal_ccc: 0.8319 - Valence_ccc: 0.4601 - Dominance_ccc: 0.8905 - val_loss: 1.2628 - val_Arousal_loss: 0.1730 - val_Valence_loss: 0.9467 - val_Dominance_loss: 0.1431 - val_Arousal_ccc: 0.8270 - val_Valence_ccc: 0.0533 - val_Dominance_ccc: 0.8569\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "\n",
    "history = model.fit(x_train_scaled, y_train_dta, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size,                     \n",
    "                    validation_data=(x_val_scaled, y_val_dta), \n",
    "                    callbacks=[callback])\n",
    "# plot_learningCurve(history, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b1b83d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 4s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48639995],\n",
       "       [0.31548062],\n",
       "       [0.49207112],\n",
       "       ...,\n",
       "       [0.29789454],\n",
       "       [0.26807895],\n",
       "       [0.19476964]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(x_val_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4bd54dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.163089</td>\n",
       "      <td>0.159229</td>\n",
       "      <td>0.207163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405032</td>\n",
       "      <td>0.354663</td>\n",
       "      <td>0.399944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.410818</td>\n",
       "      <td>0.334092</td>\n",
       "      <td>0.365697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.322820</td>\n",
       "      <td>0.287947</td>\n",
       "      <td>0.366822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.274624</td>\n",
       "      <td>0.374503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9466</th>\n",
       "      <td>0.383390</td>\n",
       "      <td>-0.080103</td>\n",
       "      <td>0.238497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9467</th>\n",
       "      <td>0.379031</td>\n",
       "      <td>-0.065992</td>\n",
       "      <td>0.242540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9468</th>\n",
       "      <td>0.382344</td>\n",
       "      <td>-0.043107</td>\n",
       "      <td>0.245435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9469</th>\n",
       "      <td>0.385036</td>\n",
       "      <td>-0.021573</td>\n",
       "      <td>0.256853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9470</th>\n",
       "      <td>0.380194</td>\n",
       "      <td>-0.005330</td>\n",
       "      <td>0.257171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9471 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Arousal   Valence  Dominance\n",
       "0     0.163089  0.159229   0.207163\n",
       "1     0.405032  0.354663   0.399944\n",
       "2     0.410818  0.334092   0.365697\n",
       "3     0.322820  0.287947   0.366822\n",
       "4     0.304500  0.274624   0.374503\n",
       "...        ...       ...        ...\n",
       "9466  0.383390 -0.080103   0.238497\n",
       "9467  0.379031 -0.065992   0.242540\n",
       "9468  0.382344 -0.043107   0.245435\n",
       "9469  0.385036 -0.021573   0.256853\n",
       "9470  0.380194 -0.005330   0.257171\n",
       "\n",
       "[9471 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4fe504aa-313b-4bb7-bda1-20c4ccb09c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  76.,  520.,  611.,  810., 1098., 1894., 2467., 1392.,  466.,\n",
       "         137.]),\n",
       " array([-0.06760712,  0.00668762,  0.08098235,  0.15527709,  0.22957182,\n",
       "         0.30386657,  0.37816128,  0.45245603,  0.52675074,  0.6010455 ,\n",
       "         0.67534024], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQoElEQVR4nO3df6zddX3H8edLUJepm8XWykqzi6bG1P1AcgcmLhPHxs8MMBpSzLQatrqtbJr5x666BIMhq8vUzIyxVW0siYLMH6ODTlYqhrkM5OIqWBhyxRLaFLiKIhsbG+69P86327Hc23Nue3vOhc/zkZyc7/f9/Xy/3/c57e3rfn+c01QVkqT2PGfcDUiSxsMAkKRGGQCS1CgDQJIaZQBIUqOOHXcDh7J8+fKamJgYdxuS9Ixyxx13fLeqVgwat6QDYGJigunp6XG3IUnPKEkeGGacp4AkqVEGgCQ1ygCQpEYNDIAkq5PcnOTuJLuTvKurfyDJviS7usc5feu8N8lMknuTnNlXP6urzSSZOjovSZI0jGEuAj8FvKeqvp7kRcAdSXZ0yz5aVX/WPzjJWmAd8GrgZ4CbkryyW3wF8OvAXuD2JNuq6u7FeCGSpIUZGABVtR/Y300/nuQeYNUhVjkfuKaqngS+k2QGOKVbNlNV9wMkuaYbawBI0hgs6BpAkgngNcBtXemSJHcm2ZJkWVdbBTzYt9rerjZf/eB9bEgynWR6dnZ2Ie1JkhZg6ABI8kLg88C7q+qHwJXAK4CT6B0hfHgxGqqqzVU1WVWTK1YM/ByDJOkwDfVBsCTPpfeP/6er6gsAVfVw3/KPA9d3s/uA1X2rn9DVOERdkjRiAwMgSYBPAvdU1Uf66sd31wcA3gh8s5veBnwmyUfoXQReA3wNCLAmyYn0/uFfB7xlsV6I1IqJqRvGtu89m84d2761+IY5Angd8FbgriS7utr7gIuSnAQUsAd4J0BV7U5yLb2Lu08BG6vqRwBJLgFuBI4BtlTV7kV7JZKkBRnmLqCv0vvt/WDbD7HO5cDlc9S3H2o9SdLo+ElgSWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElq1MAASLI6yc1J7k6yO8m7uvpxSXYkua97XtbVk+RjSWaS3Jnk5L5tre/G35dk/dF7WZKkQYY5AngKeE9VrQVeC2xMshaYAnZW1RpgZzcPcDawpntsAK6EXmAAlwKnAqcAlx4IDUnS6A0MgKraX1Vf76YfB+4BVgHnA1u7YVuBC7rp84GrqudW4MVJjgfOBHZU1aNV9X1gB3DWYr4YSdLwFnQNIMkE8BrgNmBlVe3vFj0ErOymVwEP9q22t6vNVz94HxuSTCeZnp2dXUh7kqQFGDoAkrwQ+Dzw7qr6Yf+yqiqgFqOhqtpcVZNVNblixYrF2KQkaQ5DBUCS59L7x//TVfWFrvxwd2qH7vmRrr4PWN23+gldbb66JGkMhrkLKMAngXuq6iN9i7YBB+7kWQ9c11d/W3c30GuBx7pTRTcCZyRZ1l38PaOrSZLG4NghxrwOeCtwV5JdXe19wCbg2iQXAw8AF3bLtgPnADPAE8A7AKrq0SQfBG7vxl1WVY8uxouQJC3cwACoqq8CmWfx6XOML2DjPNvaAmxZSIOSpKPDTwJLUqMMAElqlAEgSY0a5iKwpDlMTN0w7hakI+IRgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowYGQJItSR5J8s2+2geS7Euyq3uc07fsvUlmktyb5My++lldbSbJ1OK/FEnSQgxzBPAp4Kw56h+tqpO6x3aAJGuBdcCru3X+MskxSY4BrgDOBtYCF3VjJUljcuygAVV1S5KJIbd3PnBNVT0JfCfJDHBKt2ymqu4HSHJNN/buhbcsSVoMR3IN4JIkd3aniJZ1tVXAg31j9na1+epPk2RDkukk07Ozs0fQniTpUA43AK4EXgGcBOwHPrxYDVXV5qqarKrJFStWLNZmJUkHGXgKaC5V9fCB6SQfB67vZvcBq/uGntDVOERdkjQGh3UEkOT4vtk3AgfuENoGrEvy/CQnAmuArwG3A2uSnJjkefQuFG87/LYlSUdq4BFAkquB04DlSfYClwKnJTkJKGAP8E6Aqtqd5Fp6F3efAjZW1Y+67VwC3AgcA2ypqt2L/WIkScMb5i6gi+Yof/IQ4y8HLp+jvh3YvqDuJElHjZ8ElqRGGQCS1CgDQJIadVi3gUpq08TUDWPZ755N545lv892HgFIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIadey4G5COxMTUDeNuQXrG8ghAkhplAEhSowwASWqUASBJjRoYAEm2JHkkyTf7ascl2ZHkvu55WVdPko8lmUlyZ5KT+9ZZ342/L8n6o/NyJEnDGuYI4FPAWQfVpoCdVbUG2NnNA5wNrOkeG4AroRcYwKXAqcApwKUHQkOSNB4DA6CqbgEePah8PrC1m94KXNBXv6p6bgVenOR44ExgR1U9WlXfB3bw9FCRJI3Q4V4DWFlV+7vph4CV3fQq4MG+cXu72nz1p0myIcl0kunZ2dnDbE+SNMgRXwSuqgJqEXo5sL3NVTVZVZMrVqxYrM1Kkg5yuAHwcHdqh+75ka6+D1jdN+6ErjZfXZI0JocbANuAA3fyrAeu66u/rbsb6LXAY92pohuBM5Is6y7+ntHVJEljMvC7gJJcDZwGLE+yl97dPJuAa5NcDDwAXNgN3w6cA8wATwDvAKiqR5N8ELi9G3dZVR18YVmSNEIDA6CqLppn0elzjC1g4zzb2QJsWVB3kqSjxk8CS1KjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWrUwK+CkIYxMXXDuFuQtEAeAUhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGuV/CPMs43/MImlYHgFIUqMMAElqlAEgSY0yACSpUQaAJDXqiAIgyZ4kdyXZlWS6qx2XZEeS+7rnZV09ST6WZCbJnUlOXowXIEk6PItxG+gbquq7ffNTwM6q2pRkqpv/I+BsYE33OBW4snt+1vFWTEnPBEfjFND5wNZueitwQV/9quq5FXhxkuOPwv4lSUM40gAo4B+S3JFkQ1dbWVX7u+mHgJXd9Crgwb5193a1H5NkQ5LpJNOzs7NH2J4kaT5Hegrol6tqX5KXAjuS/Gv/wqqqJLWQDVbVZmAzwOTk5ILWlSQN74iOAKpqX/f8CPBF4BTg4QOndrrnR7rh+4DVfauf0NUkSWNw2EcASV4APKeqHu+mzwAuA7YB64FN3fN13SrbgEuSXEPv4u9jfaeKJGle47yxYs+mc8e276PtSE4BrQS+mOTAdj5TVV9KcjtwbZKLgQeAC7vx24FzgBngCeAdR7BvSdIROuwAqKr7gV+co/494PQ56gVsPNz9SZIWl58ElqRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNerYcTcgSUvZxNQNY9nvnk3nHvV9eAQgSY0yACSpUQaAJDXKAJCkRj2rLwKP6+KNJD0TeAQgSY0yACSpUQaAJDVq5AGQ5Kwk9yaZSTI16v1LknpGGgBJjgGuAM4G1gIXJVk7yh4kST2jPgI4BZipqvur6r+Aa4DzR9yDJInR3wa6Cniwb34vcGr/gCQbgA3d7L8luRdYDnx3JB0ePntcHPa4OOxxcYytx3xo6KFz9fizw6y45D4HUFWbgc39tSTTVTU5ppaGYo+Lwx4Xhz0ujmd7j6M+BbQPWN03f0JXkySN2KgD4HZgTZITkzwPWAdsG3EPkiRGfAqoqp5KcglwI3AMsKWqdg+x6ubBQ8bOHheHPS4Oe1wcz+oeU1WL2Ygk6RnCTwJLUqMMAElq1JIMgCTHJdmR5L7uedk8476U5AdJrh9hb4f8Koskz0/y2W75bUkmRtXbAnr8lSRfT/JUkjePur8he/zDJHcnuTPJziRD3dc84h5/J8ldSXYl+eo4PtU+7FerJHlTkkoy8lsah3gf355ktnsfdyX5raXWYzfmwu7v5O4kn1lqPSb5aN97+K0kPxi40apacg/gT4GpbnoK+NA8404HfgO4fkR9HQN8G3g58DzgG8Dag8b8HvBX3fQ64LMjfu+G6XEC+AXgKuDNY/jzHabHNwA/2U3/7hJ9H3+qb/o84EtLrcdu3IuAW4Bbgcml1iPwduAvRv33cIE9rgH+BVjWzb90qfV40Pjfp3eTzSG3uySPAOh9PcTWbnorcMFcg6pqJ/D4iHqC4b7Kor/3zwGnJ8lS6rGq9lTVncD/jLCvfsP0eHNVPdHN3krvMyNLrccf9s2+ABj1HRXDfrXKB4EPAf85yuY6z4Svfxmmx98Grqiq7wNU1SNLsMd+FwFXD9roUg2AlVW1v5t+CFg5zmb6zPVVFqvmG1NVTwGPAS8ZSXcH7b8zV4/jttAeLwb+/qh29HRD9ZhkY5Jv0ztq/YMR9XbAwB6TnAysrqpx/fd4w/5Zv6k73fe5JKvnWH40DdPjK4FXJvmnJLcmOWtk3fUM/TPTnS49EfjyoI2O7asgktwEvGyORe/vn6mqSuK9qo1K8pvAJPD6cfcyl6q6ArgiyVuAPwbWj7ml/5PkOcBH6J1iWcr+Dri6qp5M8k56R9C/OuaeDnYsvdNAp9E7Gr0lyc9X1Q/G2dQ81gGfq6ofDRo4tgCoql+bb1mSh5McX1X7kxwPjPpwaz7DfJXFgTF7kxwL/DTwvdG092P7P2Apft3GUD0m+TV6vxC8vqqeHFFvByz0fbwGuPKodvR0g3p8EfBzwFe6s5AvA7YlOa+qppdIj1RV/8/HJ+gdTY3SMH/We4Hbquq/ge8k+Ra9QLh9NC0u6O/jOmDjMBtdqqeAtvH/v0mtB64bYy/9hvkqi/7e3wx8ubqrMkuox3Eb2GOS1wB/DZw3hvOtw/a4pm/2XOC+EfYHA3qsqseqanlVTVTVBL1rKaP8x39gjwDdL3kHnAfcM8L+YLifmb+l99s/SZbTOyV0/xLrkSSvApYB/zzUVsd15X3AFe+XADvp/UDdBBzX1SeBT/SN+0dgFvgPegl95gh6Owf4Fr0r8u/vapfR+8EC+Angb4AZ4GvAy8fw/g3q8Ze69+vf6R2d7F6CPd4EPAzs6h7blmCPfw7s7vq7GXj1UuvxoLFfYcR3AQ35Pv5J9z5+o3sfX7UEewy902l3A3cB65Zaj938B4BNw27Tr4KQpEYt1VNAkqSjzACQpEYZAJLUKANAkhplAEhSowwASWqUASBJjfpfmRaguDSnvIkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f75e70a7-b4a3-4d7f-8b2a-bb5472283055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  52.,  105.,  399., 1544., 2293., 2908., 1481.,  490.,  138.,\n",
       "          61.]),\n",
       " array([-0.13312835, -0.05516669,  0.02279497,  0.10075663,  0.17871829,\n",
       "         0.25667994,  0.3346416 ,  0.41260326,  0.49056492,  0.56852658,\n",
       "         0.64648824]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_val_scaled['Dominance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084594e-9150-4f33-82f7-aaf958128497",
   "metadata": {},
   "source": [
    "### Linguistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f9e2a29-c2c0-4d0e-8e7b-92b58ff7d0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Time</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MSP-PODCAST_0021_0003</td>\n",
       "      <td>0.0-2.0</td>\n",
       "      <td>13.146256</td>\n",
       "      <td>16.753491</td>\n",
       "      <td>13.014761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MSP-PODCAST_0021_0003</td>\n",
       "      <td>0.0-2.5</td>\n",
       "      <td>12.047585</td>\n",
       "      <td>16.634094</td>\n",
       "      <td>13.112332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MSP-PODCAST_0021_0003</td>\n",
       "      <td>0.0-3.0</td>\n",
       "      <td>11.223967</td>\n",
       "      <td>16.184754</td>\n",
       "      <td>13.185027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MSP-PODCAST_0021_0003</td>\n",
       "      <td>0.0-3.5</td>\n",
       "      <td>10.706417</td>\n",
       "      <td>15.996252</td>\n",
       "      <td>12.437792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MSP-PODCAST_0021_0003</td>\n",
       "      <td>0.0-4.0</td>\n",
       "      <td>9.947854</td>\n",
       "      <td>15.493055</td>\n",
       "      <td>12.135020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41810</th>\n",
       "      <td>41810</td>\n",
       "      <td>MSP-PODCAST_1353_0041</td>\n",
       "      <td>22.0-26.0</td>\n",
       "      <td>22.044157</td>\n",
       "      <td>16.009710</td>\n",
       "      <td>14.630833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41811</th>\n",
       "      <td>41811</td>\n",
       "      <td>MSP-PODCAST_1353_0041</td>\n",
       "      <td>22.5-26.15</td>\n",
       "      <td>22.439580</td>\n",
       "      <td>16.266371</td>\n",
       "      <td>14.702753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41812</th>\n",
       "      <td>41812</td>\n",
       "      <td>MSP-PODCAST_1353_0041</td>\n",
       "      <td>23.0-26.15</td>\n",
       "      <td>22.996343</td>\n",
       "      <td>16.350448</td>\n",
       "      <td>15.013053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41813</th>\n",
       "      <td>41813</td>\n",
       "      <td>MSP-PODCAST_1353_0041</td>\n",
       "      <td>23.5-26.15</td>\n",
       "      <td>23.631934</td>\n",
       "      <td>16.277397</td>\n",
       "      <td>15.608230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41814</th>\n",
       "      <td>41814</td>\n",
       "      <td>MSP-PODCAST_1353_0041</td>\n",
       "      <td>24.0-26.15</td>\n",
       "      <td>24.508722</td>\n",
       "      <td>16.728517</td>\n",
       "      <td>16.637762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41815 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0               Filename        Time    Arousal    Valence  \\\n",
       "0               0  MSP-PODCAST_0021_0003     0.0-2.0  13.146256  16.753491   \n",
       "1               1  MSP-PODCAST_0021_0003     0.0-2.5  12.047585  16.634094   \n",
       "2               2  MSP-PODCAST_0021_0003     0.0-3.0  11.223967  16.184754   \n",
       "3               3  MSP-PODCAST_0021_0003     0.0-3.5  10.706417  15.996252   \n",
       "4               4  MSP-PODCAST_0021_0003     0.0-4.0   9.947854  15.493055   \n",
       "...           ...                    ...         ...        ...        ...   \n",
       "41810       41810  MSP-PODCAST_1353_0041   22.0-26.0  22.044157  16.009710   \n",
       "41811       41811  MSP-PODCAST_1353_0041  22.5-26.15  22.439580  16.266371   \n",
       "41812       41812  MSP-PODCAST_1353_0041  23.0-26.15  22.996343  16.350448   \n",
       "41813       41813  MSP-PODCAST_1353_0041  23.5-26.15  23.631934  16.277397   \n",
       "41814       41814  MSP-PODCAST_1353_0041  24.0-26.15  24.508722  16.728517   \n",
       "\n",
       "       Dominance  \n",
       "0      13.014761  \n",
       "1      13.112332  \n",
       "2      13.185027  \n",
       "3      12.437792  \n",
       "4      12.135020  \n",
       "...          ...  \n",
       "41810  14.630833  \n",
       "41811  14.702753  \n",
       "41812  15.013053  \n",
       "41813  15.608230  \n",
       "41814  16.637762  \n",
       "\n",
       "[41815 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e859855-8823-415d-abb4-12bfb8697797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
