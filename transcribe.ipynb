{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284d9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import io\n",
    "from google.cloud import speech\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d13719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './ABI_data/'\n",
    "audio_path = data_path + 'Audios/'\n",
    "diary_path = data_path + 'diarization/'\n",
    "temp_path = data_path + 'temp/'\n",
    "\n",
    "# This path will be followed by series name\n",
    "output_path_base = data_path + 'Transcripts/'\n",
    "lld_path = data_path + 'LLDs/'\n",
    "\n",
    "failed_path = data_path + 'transcribing_failed.txt'\n",
    "bucket_name = 'msc_research_kings'\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/changhyun/workspace/ABI_research/config/config3.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e9da33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribing():\n",
    "    client = speech.SpeechClient()\n",
    "    responses = []\n",
    "    errors = []\n",
    "    for file in os.listdir(audio_path):\n",
    "        path = os.path.join(audio_path, file)\n",
    "        with wave.open(path, \"r\") as wf:\n",
    "            channel = wf.getnchannels()\n",
    "            frame_rate = wf.getframerate()\n",
    "            with open(path, \"rb\") as audio_file:\n",
    "                content = audio_file.read()\n",
    "            audio = speech.RecognitionAudio(content=content)\n",
    "            config = speech.RecognitionConfig(\n",
    "                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "                sample_rate_hertz= frame_rate,\n",
    "                audio_channel_count=channel,\n",
    "                enable_separate_recognition_per_channel=True,\n",
    "                language_code=\"en-US\",\n",
    "            )\n",
    "            try:\n",
    "                responses.append(client.recognize(config=config, audio=audio))\n",
    "            except Exception as e:\n",
    "                print(path)\n",
    "                print(e)\n",
    "                errors.append(file)\n",
    "\n",
    "    return responses, errors\n",
    "\n",
    "\n",
    "def short_transcribe(audio_file_name):\n",
    "    client = speech.SpeechClient()\n",
    "    confidences = []\n",
    "    transcript=''\n",
    "    frame_rate, channels = frame_rate_channel(audio_file_name)\n",
    "    value = False\n",
    "#     if channels > 1:\n",
    "#         value = True\n",
    "    with io.open(audio_file_name, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=frame_rate,\n",
    "        audio_channel_count=channels,\n",
    "        enable_automatic_punctuation=True,\n",
    "        enable_separate_recognition_per_channel=False,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "    try:\n",
    "        response = client.recognize(config=config, audio=audio)\n",
    "    except:\n",
    "        print(audio_file_name)\n",
    "    \n",
    "    print(response)\n",
    "    for result in response.results:\n",
    "        transcript += result.alternatives[0].transcript\n",
    "        confidences.append(result.alternatives[0].confidence)\n",
    "\n",
    "    return transcript, mean(confidences)\n",
    "\n",
    "\n",
    "def long_transcribe(audio_file_name):\n",
    "    #     file_name = filepath + audio_file_name\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "\n",
    "    frame_rate, channels = frame_rate_channel(audio_file_name)\n",
    "\n",
    "    #     source_file_name = filepath + audio_file_name\n",
    "    destination_blob_name = audio_file_name\n",
    "\n",
    "    upload_blob(bucket_name, audio_file_name, destination_blob_name)\n",
    "\n",
    "    gcs_uri = 'gs://' + bucket_name + '/' + audio_file_name\n",
    "    transcript = ''\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "    value = False\n",
    "    if channels > 1:\n",
    "        value = True\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=frame_rate,\n",
    "        audio_channel_count=channels,\n",
    "        enable_automatic_punctuation=True,\n",
    "        enable_separate_recognition_per_channel=False,\n",
    "        language_code='en-US')\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "    response = operation.result(timeout=10000)\n",
    "    confidence = []\n",
    "    \n",
    "    print(response)\n",
    "    for result in response.results:\n",
    "        transcript += result.alternatives[0].transcript\n",
    "        confidence.append(result.alternatives[0].confidence)\n",
    "\n",
    "    delete_blob(bucket_name, destination_blob_name)\n",
    "    return transcript, mean(confidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827c3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_files_mono():\n",
    "    sample = AudioSegment.from_wav(audio_path)\n",
    "    print(sample.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0863faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_rate_channel_freq(audio_path):\n",
    "    frame_rates = {}\n",
    "    channels = {}\n",
    "    for file in os.listdir(audio_path):\n",
    "        path = os.path.join(audio_path, file)\n",
    "        with wave.open(path, \"r\") as wf:\n",
    "            frame_rate = wf.getframerate()\n",
    "            channel = wf.getnchannels()\n",
    "            freq = frame_rates.get(frame_rate, \"None\")\n",
    "            if freq == \"None\":\n",
    "                frame_rates[frame_rate] = 1\n",
    "            else:\n",
    "                frame_rates[frame_rate] += 1\n",
    "            freq = channels.get(channel, \"None\")\n",
    "            if freq == \"None\":\n",
    "                channels[channel] = 1\n",
    "            else:\n",
    "                channels[channel] += 1\n",
    "    return frame_rates, channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01c22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(li):\n",
    "    if len(li) == 0:\n",
    "        return 0\n",
    "    return sum(li) / len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d513a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def short_transcribe(audio_file_name):\n",
    "#     client = speech.SpeechClient()\n",
    "#     confidences = []\n",
    "#     transcript=''\n",
    "#     frame_rate, channels = frame_rate_channel(audio_file_name)\n",
    "#     value = False\n",
    "#     if channels > 1:\n",
    "#         value = True\n",
    "#     with io.open(audio_file_name, \"rb\") as audio_file:\n",
    "#         content = audio_file.read()\n",
    "#     audio = speech.RecognitionAudio(content=content)\n",
    "#     config = speech.RecognitionConfig(\n",
    "#         encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "#         sample_rate_hertz=frame_rate,\n",
    "#         audio_channel_count=channels,\n",
    "#         enable_separate_recognition_per_channel=value,\n",
    "#         language_code=\"en-US\",\n",
    "#     )\n",
    "#     try:\n",
    "#         response = client.recognize(config=config, audio=audio)\n",
    "#     except:\n",
    "#         print(audio_file_name)\n",
    "#     for result in response.results:\n",
    "#         transcript += result.alternatives[0].transcript\n",
    "#         confidences.append(result.alternatives[0].confidence)\n",
    "#     print(response)\n",
    "\n",
    "#     return transcript, mean(confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f2dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path+'selected.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    series = []\n",
    "    for line in lines:\n",
    "        series.append(line.strip('\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7137753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current episode: Brain Injury Today Ep1 (Keeping the brain injury community connected during the coronavirus outbreak)\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"Brain injury today is sponsored by the Washington State traumatic. Brain injury Council and produced by goal 17 media storytellers for the common good.\"\n",
      "    confidence: 0.9441017508506775\n",
      "  }\n",
      "  result_end_time {\n",
      "    seconds: 9\n",
      "    nanos: 330000000\n",
      "  }\n",
      "  language_code: \"en-us\"\n",
      "}\n",
      "total_billed_time {\n",
      "  seconds: 15\n",
      "}\n",
      "\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"Hi, everyone. This is Deborah crawling executive director for the brain injury. Alliance of Washington is an exciting day here today as we are launching our first podcast, brain injury today and we welcome all of you were going to start today with just kind of a dialogue with my board. President is joining us, Allison Molnar as we are in uncertain times of being able to really have communication with all of our community. We\\'re taking advantage of all technology has to offer and podcast or one of the ways we can all stay connected, stay informed, and continue to learn and support one another Allison. Thanks for being here.\"\n",
      "    confidence: 0.9623208045959473\n",
      "  }\n",
      "  result_end_time {\n",
      "    seconds: 52\n",
      "    nanos: 110000000\n",
      "  }\n",
      "  language_code: \"en-us\"\n",
      "}\n",
      "total_billed_time {\n",
      "  seconds: 60\n",
      "}\n",
      "\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"Hi everyone, this is Allison, Allison. Molnar I am president of brain injury Alliance. Not only am I president, I am also a client of the alliance. I was insured about 10 years ago. So I have that in common with everybody to this podcast was extremely important to me because I was sitting at home trying to digest, just what was happening in the community and I felt a strong need to change the dialogue and answer some questions. So Deborah and I sat down and tried to figure out some ways of connecting with you. And that really is, the reason, the reason why we\\'re here.\"\n",
      "    confidence: 0.9636653065681458\n",
      "  }\n",
      "  result_end_time {\n",
      "    seconds: 47\n",
      "    nanos: 10000000\n",
      "  }\n",
      "  language_code: \"en-us\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"To reach our friends, to answer your questions to have a dialogue and hopefully as we all come together, not feel so alone. Should not feel so overwhelmed and frankly not be as bored.\"\n",
      "    confidence: 0.9559261202812195\n",
      "  }\n",
      "  result_end_time {\n",
      "    seconds: 65\n",
      "    nanos: 840000000\n",
      "  }\n",
      "  language_code: \"en-us\"\n",
      "}\n",
      "total_billed_time {\n",
      "  seconds: 75\n",
      "}\n",
      "\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"I think you have struck on a cord for a few reasons. This is important. We are challenging ourselves here staff and I on ways to stay connected with our community and we don\\'t want folks to feel isolated which is already a huge issue for folks who has sustained a brain injury. And so we\\'re thinking out of our box on communication, not just hearing, what if there are answers that we have. But really, we\\'re just still trying to figure out what are the questions that folks have right now what are concerned, what are some barriers are bumps in the road that have really been affecting them on a daily basis, not that we can fix them all but that we can at least hear each other and hopefully into\"\n",
      "    confidence: 0.9667672514915466\n",
      "  }\n",
      "  result_end_time {\n",
      "    seconds: 59\n",
      "    nanos: 970000000\n",
      "  }\n",
      "  language_code: \"en-us\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"Future segments, we are going to be getting input from some of the Professionals, in our amazing Community here in Seattle and hearing from them. Some ideas on coping mechanisms, on things we can do proactively on any piece that will help us really try to figure out what is in. I believe in all of our lifetimes, one of the most challenging times we have ever been presented with\"\n",
      "    confidence: 0.9667786955833435\n",
      "  }\n",
      "  result_end_time {\n",
      "    seconds: 94\n",
      "    nanos: 560000000\n",
      "  }\n",
      "  language_code: \"en-us\"\n",
      "}\n",
      "total_billed_time {\n",
      "  seconds: 105\n",
      "}\n",
      "\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"We have fought really hard to recover and to be at where we are right now and I don\\'t know about you but I attended a support group for about 4 years and I imagine some of y\\'all did too so missing that support group is big deal or was a big deal to me. Hopefully you\\'ll tune in and listen to this and maybe use a Facebook page or write us some questions and we can be that support group. If we all come together and you won\\'t feel so long,\"\n",
      "    confidence: 0.9703666567802429\n",
      "  }\n",
      "  result_end_time {\n",
      "    seconds: 32\n",
      "    nanos: 130000000\n",
      "  }\n",
      "  language_code: \"en-us\"\n",
      "}\n",
      "total_billed_time {\n",
      "  seconds: 45\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/26 [01:28<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     transcript, conf \u001b[38;5;241m=\u001b[39m short_transcribe(temp_file_path)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     transcript, conf \u001b[38;5;241m=\u001b[39m \u001b[43mlong_transcribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conf \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to transcribe:\u001b[39m\u001b[38;5;124m\"\u001b[39m, key)\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mlong_transcribe\u001b[0;34m(audio_file_name)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Detects speech in the audio file\u001b[39;00m\n\u001b[1;32m     92\u001b[0m operation \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mlong_running_recognize(config\u001b[38;5;241m=\u001b[39mconfig, audio\u001b[38;5;241m=\u001b[39maudio)\n\u001b[0;32m---> 93\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m confidence \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/workspace/ABI_research/env/lib/python3.8/site-packages/google/api_core/future/polling.py:132\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"Get the result of the operation, blocking if necessary.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        the timeout is reached before the operation completes.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;129;01mis\u001b[39;00m DEFAULT_RETRY \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry\u001b[39m\u001b[38;5;124m\"\u001b[39m: retry}\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "File \u001b[0;32m~/workspace/ABI_research/env/lib/python3.8/site-packages/google/api_core/future/polling.py:110\u001b[0m, in \u001b[0;36mPollingFuture._blocking_poll\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;129;01mis\u001b[39;00m DEFAULT_RETRY \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry\u001b[39m\u001b[38;5;124m\"\u001b[39m: retry}\n\u001b[0;32m--> 110\u001b[0m     \u001b[43mretry_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_done_or_raise\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRetryError:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mTimeoutError(\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation did not complete within the designated \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/ABI_research/env/lib/python3.8/site-packages/google/api_core/retry.py:283\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    282\u001b[0m )\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/ABI_research/env/lib/python3.8/site-packages/google/api_core/retry.py:218\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    213\u001b[0m             sleep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(time_to_deadline, sleep)\n\u001b[1;32m    215\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying due to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, sleeping \u001b[39m\u001b[38;5;132;01m{:.1f}\u001b[39;00m\u001b[38;5;124ms ...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(last_exc, sleep)\n\u001b[1;32m    217\u001b[0m     )\n\u001b[0;32m--> 218\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSleep generator stopped yielding sleep values.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for s in series:\n",
    "    s_diaries = os.listdir(diary_path + s)\n",
    "    episodes = fnmatch.filter(s_diaries, '*_cleaned.json')\n",
    "    episodes.sort()\n",
    "\n",
    "    confidences = []\n",
    "    for episode in tqdm(episodes):\n",
    "        f = open(diary_path + s + '/' + episode)\n",
    "        data = json.load(f)\n",
    "\n",
    "        inst = episode.split('.')[0].split('_')[0]\n",
    "        audio_file_path = audio_path + s + '/' + inst + '.wav'\n",
    "        file = AudioSegment.from_wav(audio_file_path)\n",
    "        output_lld_path = lld_path + s + '/'\n",
    "        if not os.path.exists(output_lld_path):\n",
    "            os.mkdir(output_lld_path)\n",
    "\n",
    "        print('Current episode: %s' % (inst))\n",
    "\n",
    "        for key in data:\n",
    "            \n",
    "            segment = data[key]\n",
    "            start = segment['start'] * 1000\n",
    "            end = segment['end'] * 1000\n",
    "            sliced = file[start:end]\n",
    "            temp_file_path = temp_path + key + '.wav'\n",
    "            sliced.export(temp_file_path, format=\"wav\")\n",
    "            if (end - start) / 1000 < 60.0:\n",
    "                transcript, conf = short_transcribe(temp_file_path)\n",
    "            else:\n",
    "                transcript, conf = long_transcribe(temp_file_path)\n",
    "\n",
    "\n",
    "            if conf == 0:\n",
    "                print(\"Failed to transcribe:\", key)\n",
    "                fi = open(failed_path, \"a\")\n",
    "                fi.write(key + '\\n')\n",
    "                fi.close()\n",
    "\n",
    "            confidences.append(conf)\n",
    "            new_path = os.path.join(output_path_base + s, key + '.txt')\n",
    "            if not os.path.exists(output_path_base + s):\n",
    "                os.mkdir(output_path_base + s)\n",
    "#             write_transcripts(new_path, transcript)\n",
    "#             print(key, '.txt has been created')\n",
    "\n",
    "#             extracted = smile.process_file(temp_file_path)\n",
    "#             extracted.to_csv(output_lld_path + key + '.csv')\n",
    "\n",
    "            os.remove(temp_file_path)\n",
    "\n",
    "    conf_dict[inst] = confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536a3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit 60sec & 10MB\n",
    "def find_long_audios(path):\n",
    "    files = []\n",
    "    for file in os.listdir(path):\n",
    "        file_path = os.path.join(path, file)\n",
    "        size = byte_to_mb(os.path.getsize(file_path))\n",
    "        if size > 10:\n",
    "            files.append(file)\n",
    "            continue\n",
    "        with wave.open(file_path, \"r\") as wf:\n",
    "            frame_rate = wf.getframerate()\n",
    "            channel = wf.getnchannels()\n",
    "            n_frames = wf.getnframes()\n",
    "            duration = n_frames / float(frame_rate)\n",
    "            if duration > 60:\n",
    "                files.append(file)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1e9cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_to_mb(size):\n",
    "    return size / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac71bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_long_files = find_long_audios(train_path)\n",
    "test_long_files = find_long_audios(test_path)\n",
    "valid_long_files = find_long_audios(validation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b977bcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSP-PODCAST_1170_0047.wav',\n",
       " 'MSP-PODCAST_1167_0089.wav',\n",
       " 'MSP-PODCAST_0422_0206.wav',\n",
       " 'MSP-PODCAST_1170_0023.wav',\n",
       " 'MSP-PODCAST_0456_0084.wav',\n",
       " 'MSP-PODCAST_1184_0053.wav',\n",
       " 'MSP-PODCAST_0456_0086.wav',\n",
       " 'MSP-PODCAST_0422_0233.wav',\n",
       " 'MSP-PODCAST_0361_0032.wav',\n",
       " 'MSP-PODCAST_0418_0053.wav',\n",
       " 'MSP-PODCAST_1167_0092.wav',\n",
       " 'MSP-PODCAST_1167_0004.wav',\n",
       " 'MSP-PODCAST_1353_0031.wav',\n",
       " 'MSP-PODCAST_1353_0035.wav',\n",
       " 'MSP-PODCAST_0456_0077.wav',\n",
       " 'MSP-PODCAST_0380_0232.wav',\n",
       " 'MSP-PODCAST_0456_0094.wav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_long_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b1eda00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSP-PODCAST_1159_0022.wav',\n",
       " 'MSP-PODCAST_1154_0024.wav',\n",
       " 'MSP-PODCAST_0498_0348.wav',\n",
       " 'MSP-PODCAST_1130_0008.wav',\n",
       " 'MSP-PODCAST_1159_0007.wav',\n",
       " 'MSP-PODCAST_1159_0004.wav',\n",
       " 'MSP-PODCAST_1130_0002.wav',\n",
       " 'MSP-PODCAST_1154_0035.wav',\n",
       " 'MSP-PODCAST_1159_0020.wav',\n",
       " 'MSP-PODCAST_1130_0006.wav',\n",
       " 'MSP-PODCAST_1183_0037.wav',\n",
       " 'MSP-PODCAST_0538_0094.wav',\n",
       " 'MSP-PODCAST_1130_0004.wav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_long_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "179980aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSP-PODCAST_1186_0014.wav',\n",
       " 'MSP-PODCAST_1191_0026.wav',\n",
       " 'MSP-PODCAST_1186_0007.wav',\n",
       " 'MSP-PODCAST_1185_0010.wav',\n",
       " 'MSP-PODCAST_1187_0001.wav',\n",
       " 'MSP-PODCAST_1188_0023.wav',\n",
       " 'MSP-PODCAST_1186_0010.wav',\n",
       " 'MSP-PODCAST_1190_0063.wav',\n",
       " 'MSP-PODCAST_1185_0011.wav',\n",
       " 'MSP-PODCAST_1191_0010.wav',\n",
       " 'MSP-PODCAST_1187_0007.wav',\n",
       " 'MSP-PODCAST_1186_0006.wav',\n",
       " 'MSP-PODCAST_1191_0018.wav',\n",
       " 'MSP-PODCAST_1187_0015.wav',\n",
       " 'MSP-PODCAST_1191_0019.wav',\n",
       " 'MSP-PODCAST_1187_0026.wav',\n",
       " 'MSP-PODCAST_1187_0032.wav']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_long_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffd3bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ad59e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_blob(bucket_name, blob_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    blob.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "990e8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_rate_channel(audio_file_name):\n",
    "    with wave.open(audio_file_name, \"rb\") as wave_file:\n",
    "        frame_rate = wave_file.getframerate()\n",
    "        channels = wave_file.getnchannels()\n",
    "        return frame_rate,channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c324e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_transcribe(audio_file_name):\n",
    "    \n",
    "#     file_name = filepath + audio_file_name\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "    \n",
    "    frame_rate, channels = frame_rate_channel(audio_file_name)\n",
    "    \n",
    "#     source_file_name = filepath + audio_file_name\n",
    "    destination_blob_name = audio_file_name\n",
    "    \n",
    "    upload_blob(bucket_name, audio_file_name, destination_blob_name)\n",
    "    \n",
    "    gcs_uri = 'gs://' + bucket_name + '/' + audio_file_name\n",
    "    transcript = ''\n",
    "    \n",
    "    client = speech.SpeechClient()\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "    value = False\n",
    "    if channels > 1:\n",
    "        value = True\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=frame_rate,\n",
    "        audio_channel_count=channels,\n",
    "        enable_separate_recognition_per_channel=value,\n",
    "        language_code='en-US')\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "    response = operation.result(timeout=10000)\n",
    "    confidence = []\n",
    "\n",
    "    for result in response.results:\n",
    "        transcript += result.alternatives[0].transcript\n",
    "        confidence.append(result.alternatives[0].confidence)\n",
    "    \n",
    "    delete_blob(bucket_name, destination_blob_name)\n",
    "    return transcript, mean(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fba86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_transcripts(transcript_filename,transcript):\n",
    "    f= open(transcript_filename,\"w+\")\n",
    "    f.write(transcript)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9ce0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in tqdm(train_long_files):\n",
    "#     file_name = os.path.join(train_path, file)\n",
    "#     transcript = google_transcribe(file_name)\n",
    "#     write_path = os.path.join(train_write_path, file[0:21] + '.txt')\n",
    "#     write_transcripts(write_path, transcript)\n",
    "#     print(file[0:21], '.txt has been created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4a68c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▍                                        | 1/13 [00:26<05:19, 26.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1159_0022 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▊                                     | 2/13 [00:46<04:10, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1154_0024 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████▏                                 | 3/13 [01:57<07:27, 44.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_0498_0348 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████▌                              | 4/13 [02:23<05:37, 37.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1130_0008 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████▉                           | 5/13 [03:05<05:11, 38.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1159_0007 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████▎                       | 6/13 [04:10<05:34, 47.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1159_0004 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████▋                    | 7/13 [04:48<04:27, 44.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1130_0002 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████                 | 8/13 [05:28<03:35, 43.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1154_0035 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████████████████████████████▍             | 9/13 [06:14<02:56, 44.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1159_0020 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████          | 10/13 [06:54<02:08, 42.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1130_0006 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████▍      | 11/13 [07:32<01:22, 41.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1183_0037 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████▋   | 12/13 [07:52<00:34, 34.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_0538_0094 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 13/13 [08:23<00:00, 38.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1130_0004 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_confidence = []\n",
    "for file in tqdm(test_long_files):\n",
    "    file_name = os.path.join(test_path, file)\n",
    "    transcript, confidence = google_transcribe(file_name)\n",
    "    test_confidence.append(confidence)\n",
    "    write_path = os.path.join(test_write_path, file[0:21] + '.txt')\n",
    "    write_transcripts(write_path, transcript)\n",
    "    print(file[0:21], '.txt has been created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb2ba01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9495081007480621,\n",
       " 0.9791086912155151,\n",
       " 0.9364469528198243,\n",
       " 0.9494617581367493,\n",
       " 0.9273580511411031,\n",
       " 0.8997351825237274,\n",
       " 0.967968612909317,\n",
       " 0.9590785106023153,\n",
       " 0.7883926033973694,\n",
       " 0.9483107626438141,\n",
       " 0.9263116896152497,\n",
       " 0.9501621723175049,\n",
       " 0.9424928625424703]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f24320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                         | 1/17 [00:18<05:02, 18.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1186_0014 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████▏                                      | 2/17 [00:58<07:44, 30.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1191_0026 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████▊                                    | 3/17 [01:14<05:39, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1186_0007 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████▎                                 | 4/17 [02:00<07:05, 32.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1185_0010 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|████████████▉                               | 5/17 [02:38<06:55, 34.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1187_0001 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████▌                            | 6/17 [03:35<07:45, 42.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1188_0023 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|██████████████████                          | 7/17 [04:05<06:21, 38.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1186_0010 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████▋                       | 8/17 [04:52<06:09, 41.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1190_0063 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████▎                    | 9/17 [05:17<04:47, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1185_0011 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████████████████████████▎                 | 10/17 [05:44<03:53, 33.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1191_0010 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████▊               | 11/17 [06:13<03:11, 31.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1187_0007 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|██████████████████████████████▎            | 12/17 [06:56<02:57, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1186_0006 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████▉          | 13/17 [07:19<02:06, 31.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1191_0018 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████▍       | 14/17 [07:33<01:18, 26.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1187_0015 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|█████████████████████████████████████▉     | 15/17 [07:52<00:48, 24.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1191_0019 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|████████████████████████████████████████▍  | 16/17 [08:20<00:25, 25.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1187_0026 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 17/17 [08:58<00:00, 31.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP-PODCAST_1187_0032 .txt has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validation_confidence = []\n",
    "for file in tqdm(valid_long_files):\n",
    "    file_name = os.path.join(validation_path, file)\n",
    "    transcript, confidence = google_transcribe(file_name)\n",
    "    validation_confidence.append(confidence)\n",
    "    write_path = os.path.join(validation_write_path, file[0:21] + '.txt')\n",
    "    write_transcripts(write_path, transcript)\n",
    "    print(file[0:21], '.txt has been created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bd4e952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9499222040176392,\n",
       " 0.9642936885356903,\n",
       " 0.9638748466968536,\n",
       " 0.9199155569076538,\n",
       " 0.9694797843694687,\n",
       " 0.9587657898664474,\n",
       " 0.9480800032615662,\n",
       " 0.9034708042939504,\n",
       " 0.963307335972786,\n",
       " 0.9440132677555084,\n",
       " 0.9383042305707932,\n",
       " 0.9420467913150787,\n",
       " 0.9685478806495667,\n",
       " 0.96807461977005,\n",
       " 0.9333463907241821,\n",
       " 0.9595717936754227,\n",
       " 0.8928799304095182]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f38cf0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "abi_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
