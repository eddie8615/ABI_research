{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "19e57feb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "from pyannote.audio import Pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6467bdbc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6cbfb007",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                       | 2/56 [10:28<4:42:54, 314.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [114]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m tqdm(files):\n\u001B[1;32m     17\u001B[0m     inst \u001B[38;5;241m=\u001B[39m file\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m---> 18\u001B[0m     diarization \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mpodcast\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     diary \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n\u001B[1;32m     21\u001B[0m     last_speaker \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyannote/audio/core/pipeline.py:210\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[0;34m(self, file, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpreprocessors\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    208\u001B[0m     file \u001B[38;5;241m=\u001B[39m ProtocolFile(file, lazy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocessors)\n\u001B[0;32m--> 210\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyannote/audio/pipelines/speaker_diarization.py:452\u001B[0m, in \u001B[0;36mSpeakerDiarization.apply\u001B[0;34m(self, file, num_speakers, min_speakers, max_speakers, hook)\u001B[0m\n\u001B[1;32m    449\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 452\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_embeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    454\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbinarized_segmentations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexclude_overlap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding_exclude_overlap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    457\u001B[0m     hook(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m, embeddings)\n\u001B[1;32m    458\u001B[0m     \u001B[38;5;66;03m#   shape: (num_chunks, local_num_speakers, dimension)\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyannote/audio/pipelines/speaker_diarization.py:306\u001B[0m, in \u001B[0;36mSpeakerDiarization.get_embeddings\u001B[0;34m(self, file, binary_segmentations, exclude_overlap)\u001B[0m\n\u001B[1;32m    298\u001B[0m batches \u001B[38;5;241m=\u001B[39m batchify(\n\u001B[1;32m    299\u001B[0m     iter_waveform_and_mask(),\n\u001B[1;32m    300\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_batch_size,\n\u001B[1;32m    301\u001B[0m     fillvalue\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    302\u001B[0m )\n\u001B[1;32m    304\u001B[0m embedding_batches \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 306\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m batches:\n\u001B[1;32m    307\u001B[0m     waveforms, masks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m b: b[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, batch))\n\u001B[1;32m    309\u001B[0m     waveform_batch \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mvstack(waveforms)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyannote/audio/pipelines/speaker_diarization.py:274\u001B[0m, in \u001B[0;36mSpeakerDiarization.get_embeddings.<locals>.iter_waveform_and_mask\u001B[0;34m()\u001B[0m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21miter_waveform_and_mask\u001B[39m():\n\u001B[1;32m    268\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (chunk, masks), (_, clean_masks) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\n\u001B[1;32m    269\u001B[0m         binary_segmentations, clean_segmentations\n\u001B[1;32m    270\u001B[0m     ):\n\u001B[1;32m    271\u001B[0m         \u001B[38;5;66;03m# chunk: Segment(t, t + duration)\u001B[39;00m\n\u001B[1;32m    272\u001B[0m         \u001B[38;5;66;03m# masks: (num_frames, local_num_speakers) np.ndarray\u001B[39;00m\n\u001B[0;32m--> 274\u001B[0m         waveform, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_audio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m            \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m            \u001B[49m\u001B[43mduration\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mduration\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpad\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;66;03m# waveform: (1, num_samples) torch.Tensor\u001B[39;00m\n\u001B[1;32m    281\u001B[0m \n\u001B[1;32m    282\u001B[0m         \u001B[38;5;66;03m# mask may contain NaN (in case of partial stitching)\u001B[39;00m\n\u001B[1;32m    283\u001B[0m         masks \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan_to_num(masks, nan\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyannote/audio/core/io.py:417\u001B[0m, in \u001B[0;36mAudio.crop\u001B[0;34m(self, file, segment, duration, mode)\u001B[0m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpad\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    415\u001B[0m     data \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mpad(data, (pad_start, pad_end))\n\u001B[0;32m--> 417\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownmix_and_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_rate\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pyannote/audio/core/io.py:214\u001B[0m, in \u001B[0;36mAudio.downmix_and_resample\u001B[0;34m(self, waveform, sample_rate)\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;66;03m# resample\u001B[39;00m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msample_rate \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msample_rate \u001B[38;5;241m!=\u001B[39m sample_rate):\n\u001B[0;32m--> 214\u001B[0m     waveform \u001B[38;5;241m=\u001B[39m \u001B[43mtorchaudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwaveform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample_rate\u001B[49m\n\u001B[1;32m    216\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m     sample_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msample_rate\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m waveform, sample_rate\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torchaudio/functional/functional.py:1453\u001B[0m, in \u001B[0;36mresample\u001B[0;34m(waveform, orig_freq, new_freq, lowpass_filter_width, rolloff, resampling_method, beta)\u001B[0m\n\u001B[1;32m   1449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m waveform\n\u001B[1;32m   1451\u001B[0m gcd \u001B[38;5;241m=\u001B[39m math\u001B[38;5;241m.\u001B[39mgcd(\u001B[38;5;28mint\u001B[39m(orig_freq), \u001B[38;5;28mint\u001B[39m(new_freq))\n\u001B[0;32m-> 1453\u001B[0m kernel, width \u001B[38;5;241m=\u001B[39m \u001B[43m_get_sinc_resample_kernel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1454\u001B[0m \u001B[43m    \u001B[49m\u001B[43morig_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1455\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnew_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1456\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgcd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1457\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlowpass_filter_width\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1458\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrolloff\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1459\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresampling_method\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1460\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1461\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwaveform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1462\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwaveform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1463\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1464\u001B[0m resampled \u001B[38;5;241m=\u001B[39m _apply_sinc_resample_kernel(waveform, orig_freq, new_freq, gcd, kernel, width)\n\u001B[1;32m   1465\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resampled\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torchaudio/functional/functional.py:1362\u001B[0m, in \u001B[0;36m_get_sinc_resample_kernel\u001B[0;34m(orig_freq, new_freq, gcd, lowpass_filter_width, rolloff, resampling_method, beta, device, dtype)\u001B[0m\n\u001B[1;32m   1360\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(new_freq):\n\u001B[1;32m   1361\u001B[0m     t \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m-\u001B[39mi \u001B[38;5;241m/\u001B[39m new_freq \u001B[38;5;241m+\u001B[39m idx \u001B[38;5;241m/\u001B[39m orig_freq) \u001B[38;5;241m*\u001B[39m base_freq\n\u001B[0;32m-> 1362\u001B[0m     t \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclamp_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mlowpass_filter_width\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlowpass_filter_width\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1364\u001B[0m     \u001B[38;5;66;03m# we do not use built in torch windows here as we need to evaluate the window\u001B[39;00m\n\u001B[1;32m   1365\u001B[0m     \u001B[38;5;66;03m# at specific positions, not over a regular grid.\u001B[39;00m\n\u001B[1;32m   1366\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m resampling_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msinc_interpolation\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "data_path = './ABI_data/Audios/'\n",
    "diary_path = data_path + 'diarization/'\n",
    "if not os.path.exists(diary_path):\n",
    "    os.mkdir(diary_path)\n",
    "series = sorted(os.listdir(data_path))\n",
    "\n",
    "min_duration = 0.5 # 500ms\n",
    "for podcast in series:\n",
    "    files = fnmatch.filter(os.listdir(data_path+podcast), '*.wav')\n",
    "    files.sort()\n",
    "    output_path = diary_path + podcast + '/'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    \n",
    "    count = 1\n",
    "    for file in tqdm(files):\n",
    "        inst = file.split('.')[0]\n",
    "        diarization = pipeline(data_path+podcast+'/'+file)\n",
    "        diary = dict()\n",
    "        \n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            \n",
    "            detail = dict()\n",
    "            detail['episode'] = inst\n",
    "            detail['start'] = turn.start\n",
    "            detail['end'] = turn.end\n",
    "            detail['speaker'] = last_speaker\n",
    "\n",
    "            key = podcast + '_' + str(count).zfill(5)\n",
    "            diary[key] = detail\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "#             print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "        with open(output_path+inst+'.json', \"w\") as outfile:\n",
    "            json.dump(diary, outfile, indent=4)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "81640766",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adventures in Brain Injury by Calvin Balaster_00001': {'start': 3395.5621875000006,\n",
       "  'end': 3398.9878125000005,\n",
       "  'speaker': 'SPEAKER_00'}}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3417774c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adventures in Brain Injury - Ep 10 (Cristabelle Braden & Finding Hope After Head Injury).wav',\n",
       " 'Adventures in Brain Injury - Ep 11 (Kimberly Archie).wav',\n",
       " 'Adventures in Brain Injury - Ep 12 (Gabrielle Guetta & TBI Model Systems Centres).wav',\n",
       " 'Adventures in Brain Injury - Ep 13 (Healing & Success through Visualisation with Dr.wav',\n",
       " 'Adventures in Brain Injury - Ep 14 (Celebrating Five Years Since my Brain Injury).wav',\n",
       " 'Adventures in Brain Injury - Ep 15 (Brain Tumours, ABI, and Plasticity with Michelle Malmberg - Part 1).wav',\n",
       " 'Adventures in Brain Injury - Ep 16 (Relaying TBI Experiences with Tim Page).wav',\n",
       " 'Adventures in Brain Injury - Ep 17 (The Power of Functional Neurology - This stuff is so cool!).wav',\n",
       " 'Adventures in Brain Injury - Ep 18 (Empathy in Practice - From Patient to Doctor).wav',\n",
       " 'Adventures in Brain Injury - Ep 19 (Alessandra Wall).wav',\n",
       " 'Adventures in Brain Injury - Ep 20 (Dr.wav',\n",
       " 'Adventures in Brain Injury - Ep 21 (Dr.wav',\n",
       " 'Adventures in Brain Injury - Ep 22 (Dr Joshua Flowers).wav',\n",
       " 'Adventures in Brain Injury - Ep 23 (Shine On With Dr.wav',\n",
       " 'Adventures in Brain Injury - Ep 24 (An Aware Winning Novel Treatment for Brain Injury).wav',\n",
       " 'Adventures in Brain Injury - Ep 24 (Indrani Das mixdown2.wav',\n",
       " 'Adventures in Brain Injury - Ep 25 (Dr Robert Sanet).wav',\n",
       " 'Adventures in Brain Injury - Ep 26 (Kelsey Brenner).wav',\n",
       " 'Adventures in Brain Injury - Ep 27 (How Nutrition Saved My Life).wav',\n",
       " 'Adventures in Brain Injury - Ep 28 (Keiser).wav',\n",
       " 'Adventures in Brain Injury - Ep 29 (Dr.wav',\n",
       " 'Adventures in Brain Injury - Ep 30 (Music & the Brain).wav',\n",
       " 'Adventures in Brain Injury - Ep 31 (Jarod Nieder Final).wav',\n",
       " 'Adventures in Brain Injury - Ep 32 (The Inflammatory Tailspin of Brain Injury).wav',\n",
       " 'Adventures in Brain Injury - Ep 33 (The Difference Between Fixing and Healing).wav',\n",
       " \"Adventures in Brain Injury - Ep 34 (Post Concussion Syndrome - It's All in Your Head).wav\",\n",
       " \"Adventures in Brain Injury - Ep 36 (Anti-Anxiety Diet and Supplementation - The 6 Foundational R's to Your Health).wav\",\n",
       " 'Adventures in Brain Injury - Ep 37 (Neurosage - The Video Game that Can Reboot Your Brain!).wav',\n",
       " 'Adventures in Brain Injury - Ep 38 (The Keto Doctor - Is Keto Actually Healthy).wav',\n",
       " 'Adventures in Brain Injury - Ep 39 (Broad Spectrum Micronutrients and Brain Health).wav',\n",
       " 'Adventures in Brain Injury - Ep 4.wav',\n",
       " \"Adventures in Brain Injury - Ep 40 (Healthcare's Conscious Evolution - The LOVE of The Practice).wav\",\n",
       " 'Adventures in Brain Injury - Ep 41 (The Magic of Our Thoughts and Attention - Cavin Vs.wav',\n",
       " 'Adventures in Brain Injury - Ep 42 (Keto for Brain Health, Seizures and Self-Care).wav',\n",
       " 'Adventures in Brain Injury - Ep 43 (Speech, Language and Neurology).wav',\n",
       " 'Adventures in Brain Injury - Ep 44 (How to Get What You Want From Your Doctor - Patient Empowerment).wav',\n",
       " 'Adventures in Brain Injury - Ep 45 (What Have You Done for Your Brain Lately).wav',\n",
       " 'Adventures in Brain Injury - Ep 46 (Using Nutrition with Neuro-Feedback Can Improve Your Brain).wav',\n",
       " 'Adventures in Brain Injury - Ep 47 (Qualifications from Experiences and Outcome).wav',\n",
       " 'Adventures in Brain Injury - Ep 48 (The Eye Exam Upgrade - Leaving 20-20 in The 20th Century).wav',\n",
       " \"Adventures in Brain Injury - Ep 49 (Filling the Gap in Medicine The Hero's Journey of a Health Crisis).wav\",\n",
       " 'Adventures in Brain Injury - Ep 5.wav',\n",
       " 'Adventures in Brain Injury - Ep 50 (How to Rock Your Life in The Face of Adversity And The Hemp Revolution).wav',\n",
       " 'Adventures in Brain Injury - Ep 51 (Your Best Sleep Ever!).wav',\n",
       " 'Adventures in Brain Injury - Ep 52 (More for Your Mitochondria).wav',\n",
       " 'Adventures in Brain Injury - Ep 53 (Antiviral Nutrition with Dr.wav',\n",
       " 'Adventures in Brain Injury - Ep 55 (The Politics of a Pandemic with Alex Vasquez, DO, DC, ND).wav',\n",
       " 'Adventures in Brain Injury - Ep 56 (4 Components of Successful Viral Treatment with Alex Vasquez, DO, DC, ND).wav',\n",
       " 'Adventures in Brain Injury - Ep 57 (Fixing the Brain with Dr.wav',\n",
       " 'Adventures in Brain Injury - Ep 59 (Essential Oils to Boost the Brain with Jodi Cohen).wav',\n",
       " 'Adventures in Brain Injury - Ep 6.wav',\n",
       " 'Adventures in Brain Injury - Ep 60 (A Better Brain Through Nutrition with Julia Rucklidge, PhD).wav',\n",
       " 'Adventures in Brain Injury - Ep 63 (Health, Medical Empowerment, and Confidence with Elle Russ (EXPLICIT)).wav',\n",
       " 'Adventures in Brain Injury - Ep 7.wav',\n",
       " 'Adventures in Brain Injury - Ep 8.wav',\n",
       " 'Adventures in Brain Injury - Ep 9.wav']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e7053",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}